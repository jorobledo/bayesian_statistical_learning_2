{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib notebook\n",
    "%matplotlib widget\n",
    "##%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c21c28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import is_interactive\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import extract_model_params, fig_ax_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5786965",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Generate toy 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MexicanHat:\n",
    "    def __init__(self, xlim, ylim, nx, ny, mode, **kwds):\n",
    "        self.xlim = xlim\n",
    "        self.ylim = ylim\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        self.xg, self.yg = self._get_xy_grid()\n",
    "        self.XG, self.YG = self._get_meshgrids(self.xg, self.yg)\n",
    "        self.X = self._make_X(mode)\n",
    "        self.z = self.func(self.X)\n",
    "\n",
    "    def _make_X(self, mode=\"grid\"):\n",
    "        if mode == \"grid\":\n",
    "            X = torch.empty((self.nx * self.ny, 2))\n",
    "            X[:, 0] = self.XG.flatten()\n",
    "            X[:, 1] = self.YG.flatten()\n",
    "        elif mode == \"rand\":\n",
    "            X = torch.rand(self.nx * self.ny, 2)\n",
    "            X[:, 0] = X[:, 0] * (self.xlim[1] - self.xlim[0]) + self.xlim[0]\n",
    "            X[:, 1] = X[:, 1] * (self.ylim[1] - self.ylim[0]) + self.ylim[0]\n",
    "        return X\n",
    "\n",
    "    def _get_xy_grid(self):\n",
    "        x = torch.linspace(self.xlim[0], self.xlim[1], self.nx)\n",
    "        y = torch.linspace(self.ylim[0], self.ylim[1], self.ny)\n",
    "        return x, y\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_meshgrids(xg, yg):\n",
    "        return torch.meshgrid(xg, yg, indexing=\"ij\")\n",
    "\n",
    "    @staticmethod\n",
    "    def func(X):\n",
    "        r = torch.sqrt((X**2).sum(axis=1))\n",
    "        return torch.sin(r) / r\n",
    "\n",
    "    @staticmethod\n",
    "    def n2t(x):\n",
    "        return torch.from_numpy(x)\n",
    "\n",
    "    def apply_scalers(self, x_scaler, y_scaler):\n",
    "        self.X = self.n2t(x_scaler.transform(self.X))\n",
    "        Xtmp = x_scaler.transform(torch.stack((self.xg, self.yg), dim=1))\n",
    "        self.XG, self.YG = self._get_meshgrids(\n",
    "            self.n2t(Xtmp[:, 0]), self.n2t(Xtmp[:, 1])\n",
    "        )\n",
    "        self.z = self.n2t(y_scaler.transform(self.z[:, None])[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = MexicanHat(\n",
    "    xlim=[-15, 25], ylim=[-15, 5], nx=20, ny=20, mode=\"rand\"\n",
    ")\n",
    "x_scaler = StandardScaler().fit(data_train.X)\n",
    "y_scaler = StandardScaler().fit(data_train.z[:, None])\n",
    "data_train.apply_scalers(x_scaler, y_scaler)\n",
    "\n",
    "data_pred = MexicanHat(\n",
    "    xlim=[-15, 25], ylim=[-15, 5], nx=100, ny=100, mode=\"grid\"\n",
    ")\n",
    "data_pred.apply_scalers(x_scaler, y_scaler)\n",
    "\n",
    "# train inputs\n",
    "X_train = data_train.X\n",
    "\n",
    "# inputs for prediction and plotting\n",
    "X_pred = data_pred.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523c08d",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_noise = False\n",
    "use_gap = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4592094",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "##use_noise = True\n",
    "##use_gap = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865866ea",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##use_noise = False\n",
    "##use_gap = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_noise:\n",
    "    # noisy train data\n",
    "    noise_std = 0.2\n",
    "    noise_dist = torch.distributions.Normal(loc=0, scale=noise_std)\n",
    "    y_train = data_train.z + noise_dist.sample_n(len(data_train.z))\n",
    "else:\n",
    "    # noise-free train data\n",
    "    noise_std = 0\n",
    "    y_train = data_train.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af637911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut out part of the train data to create out-of-distribution predictions\n",
    "\n",
    "if use_gap:\n",
    "    mask = (X_train[:, 0] > 0) & (X_train[:, 1] < 0)\n",
    "    X_train = X_train[~mask, :]\n",
    "    y_train = y_train[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = fig_ax_3d()\n",
    "s0 = ax.plot_surface(\n",
    "    data_pred.XG,\n",
    "    data_pred.YG,\n",
    "    data_pred.z.reshape((data_pred.nx, data_pred.ny)),\n",
    "    color=\"tab:grey\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "s1 = ax.scatter(\n",
    "    xs=X_train[:, 0],\n",
    "    ys=X_train[:, 1],\n",
    "    zs=y_train,\n",
    "    color=\"tab:blue\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.set_xlabel(\"X_0\")\n",
    "ax.set_ylabel(\"X_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bf4e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Define GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52834c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    \"\"\"API:\n",
    "\n",
    "    model.forward()             prior                   f_pred\n",
    "    model()                     posterior               f_pred\n",
    "\n",
    "    likelihood(model.forward()) prior with noise        y_pred\n",
    "    likelihood(model())         posterior with noise    y_pred\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, y_train, likelihood):\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The prior, defined in terms of the mean and covariance function.\"\"\"\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X_train, y_train, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcef3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25397c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default start hyper params\n",
    "pprint(extract_model_params(model, raw=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94067cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new start hyper params\n",
    "model.mean_module.constant = 0.0\n",
    "model.covar_module.base_kernel.lengthscale = 3.0\n",
    "model.covar_module.outputscale = 8.0\n",
    "model.likelihood.noise_covar.noise = 0.1\n",
    "\n",
    "pprint(extract_model_params(model, raw=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1a9ee",
   "metadata": {},
   "source": [
    "# Fit GP to data: optimize hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train mode\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.2)\n",
    "loss_func = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "n_iter = 300\n",
    "history = defaultdict(list)\n",
    "for ii in range(n_iter):\n",
    "    optimizer.zero_grad()\n",
    "    loss = -loss_func(model(X_train), y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (ii + 1) % 10 == 0:\n",
    "        print(f\"iter {ii+1}/{n_iter}, {loss=:.3f}\")\n",
    "    for p_name, p_val in extract_model_params(model).items():\n",
    "        history[p_name].append(p_val)\n",
    "    history[\"loss\"].append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = len(history)\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=1, figsize=(ncols * 5, 5))\n",
    "for ax, (p_name, p_lst) in zip(axs, history.items()):\n",
    "    ax.plot(p_lst)\n",
    "    ax.set_title(p_name)\n",
    "    ax.set_xlabel(\"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of optimized hyper params\n",
    "pprint(extract_model_params(model, raw=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f74f7",
   "metadata": {},
   "source": [
    "# Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e18623",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    post_pred_f = model(X_pred)\n",
    "    post_pred_y = likelihood(model(X_pred))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    ax.plot_surface(\n",
    "        data_pred.XG,\n",
    "        data_pred.YG,\n",
    "        data_pred.z.reshape((data_pred.nx, data_pred.ny)),\n",
    "        color=\"tab:grey\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.plot_surface(\n",
    "        data_pred.XG,\n",
    "        data_pred.YG,\n",
    "        post_pred_y.mean.reshape((data_pred.nx, data_pred.ny)),\n",
    "        color=\"tab:red\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.set_xlabel(\"X_0\")\n",
    "    ax.set_ylabel(\"X_1\")\n",
    "\n",
    "assert (post_pred_f.mean == post_pred_y.mean).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e453d",
   "metadata": {},
   "source": [
    "# Plot difference to ground truth and uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f294c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=1, figsize=(ncols * 7, 5))\n",
    "\n",
    "vmax = post_pred_y.stddev.max()\n",
    "cs = []\n",
    "\n",
    "cs.append(\n",
    "    axs[0].contourf(\n",
    "        data_pred.XG,\n",
    "        data_pred.YG,\n",
    "        torch.abs(post_pred_y.mean - data_pred.z).reshape(\n",
    "            (data_pred.nx, data_pred.ny)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "axs[0].set_title(\"|y_pred - y_true|\")\n",
    "\n",
    "cs.append(\n",
    "    axs[1].contourf(\n",
    "        data_pred.XG,\n",
    "        data_pred.YG,\n",
    "        post_pred_f.stddev.reshape((data_pred.nx, data_pred.ny)),\n",
    "        vmin=0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    ")\n",
    "axs[1].set_title(\"f_std (epistemic)\")\n",
    "\n",
    "cs.append(\n",
    "    axs[2].contourf(\n",
    "        data_pred.XG,\n",
    "        data_pred.YG,\n",
    "        post_pred_y.stddev.reshape((data_pred.nx, data_pred.ny)),\n",
    "        vmin=0,\n",
    "        vmax=vmax,\n",
    "    )\n",
    ")\n",
    "axs[2].set_title(\"y_std (epistemic + aleatoric)\")\n",
    "\n",
    "for ax, c in zip(axs, cs):\n",
    "    ax.set_xlabel(\"X_0\")\n",
    "    ax.set_ylabel(\"X_1\")\n",
    "    ax.scatter(x=X_train[:, 0], y=X_train[:, 1], color=\"white\", alpha=0.2)\n",
    "    fig.colorbar(c, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04257cea",
   "metadata": {},
   "source": [
    "# Check learned noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d966f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((post_pred_y.stddev**2 - post_pred_f.stddev**2).mean().sqrt())\n",
    "print(\n",
    "    np.sqrt(\n",
    "        extract_model_params(model, raw=False)[\"likelihood.noise_covar.noise\"]\n",
    "    )\n",
    ")\n",
    "print(noise_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da209ff",
   "metadata": {},
   "source": [
    "# Plot confidence bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = post_pred_y.mean.reshape((data_pred.nx, data_pred.ny))\n",
    "y_std = post_pred_y.stddev.reshape((data_pred.nx, data_pred.ny))\n",
    "upper = y_mean + 2 * y_std\n",
    "lower = y_mean - 2 * y_std\n",
    "\n",
    "fig, ax = fig_ax_3d()\n",
    "for Z, color in [(upper, \"tab:green\"), (lower, \"tab:red\")]:\n",
    "    ax.plot_surface(\n",
    "        data_pred.XG,\n",
    "        data_pred.YG,\n",
    "        Z,\n",
    "        color=color,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "contour_z = lower.min() - 1\n",
    "zlim = ax.get_xlim()\n",
    "ax.set_zlim((contour_z, zlim[1] + abs(contour_z)))\n",
    "ax.contourf(data_pred.XG, data_pred.YG, y_std, zdir=\"z\", offset=contour_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running as script\n",
    "if not is_interactive():\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
